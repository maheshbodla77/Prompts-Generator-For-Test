{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain chromadb sentence-transformers ollama pandas openpyxl\n",
    "#%pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mbodla/Documents/Webinar Sesssions - AI/AIWebinar/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sx/jdc7r4cj4mg159qbrg9k88g80000gq/T/ipykernel_29279/2625694685.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Step 1: Load Excel and Convert to LangChain Documents (Run Once) ===\n",
    "df = pd.read_excel(\"CPQCOE-AutomatedTestCases-Scope.xlsx\")\n",
    "df.fillna(\"\", inplace=True)\n",
    "\n",
    "def build_context(row):\n",
    "    return f\"\"\"\n",
    "TC_ID: {row['TC_ID']}\n",
    "Automated Test script Name: {row['Automated Test script Name']}\n",
    "Quote Creation Source: {row['Quote Creation Source']}\n",
    "Copy Quote: {row['Copy Quote']}\n",
    "LOB: {row['LOB']}\n",
    "Sales Channel: {row['Sales Channel']}\n",
    "Transaction Type: {row['TransactionType']}\n",
    "OperationType: {row['OperationType']}\n",
    "Product Configuration: {row['Product Configuration']}\n",
    "Store Acceptance Type: {row['Store Acceptance Type']}\n",
    "Customer Type: {row['Customer Type']}\n",
    "Comments: {row['Comments']}\n",
    "\"\"\"\n",
    "\n",
    "documents = [Document(page_content=build_context(row)) for _, row in df.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sx/jdc7r4cj4mg159qbrg9k88g80000gq/T/ipykernel_29279/602267539.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
      "/Users/mbodla/Documents/Webinar Sesssions - AI/AIWebinar/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "# === Step 2: Create or Load Vector Store (Only Once) ===\n",
    "# Chunking the documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunked_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create embeddings and vector store based on chunks\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "faiss_index_path = \"faiss_index.pkl\"\n",
    "\n",
    "if os.path.exists(faiss_index_path):\n",
    "    with open(faiss_index_path, \"rb\") as f:\n",
    "        vectorstore = pickle.load(f)\n",
    "else:\n",
    "    vectorstore = FAISS.from_documents(chunked_documents, embedding_model)\n",
    "    with open(faiss_index_path, \"wb\") as f:\n",
    "        pickle.dump(vectorstore, f)\n",
    "\n",
    "# Create vector store retriever\n",
    "vector_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Create BM25 retriever\n",
    "keyword_retriever = BM25Retriever.from_documents(chunked_documents)\n",
    "\n",
    "\n",
    "#Ensemble Retriever\n",
    "retriever = EnsembleRetriever(retrievers=[vector_retriever,\n",
    "                                                   keyword_retriever],\n",
    "                                       weights=[0.5, 0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Define Mistral via Ollama + Prompt ===\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    template=\"\"\"\n",
    "You are a QA assistant helping map keyword-based queries to test cases.\n",
    "\n",
    "Given the following keywords:\n",
    "\"{query}\"\n",
    "\n",
    "And the following test case descriptions:\n",
    "{context}\n",
    "\n",
    "Return a list of the most relevant TC_IDs that match the query.\n",
    "For each TC_ID, include a short explanation why it's relevant.\n",
    "Only respond with actual TC_IDs from the input.\n",
    "at the end of the response only print the TC_IDs, separated by commas.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only TC_ID's from the response\n",
    "def extract_tc_ids(response):\n",
    "    \"\"\"\n",
    "    Extracts TC_IDs from the given response string.\n",
    "\n",
    "    Args:\n",
    "        response (str): The response string containing TC_IDs and explanations.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted TC_IDs.\n",
    "    \"\"\"\n",
    "    return [line.split(\":\")[1].strip() for line in response.split(\"\\n\") if line.startswith(\"TC_ID\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 4: User Query Loop ===\n",
    "\n",
    "def Conversation():\n",
    "    print(\"Chatbot: Hello! I'm QA Agent. Please enter your keywords to retrieve the corresponding TC_ID's.\\nType 'bye' to exit.\")\n",
    "    print(\"\\n‚úÖ Ready to search test cases! Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"üîç Enter comma-separated keywords: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        query = \" \".join(user_input.split(\",\"))\n",
    "        print(f\"\\nüîë Keywords entered: {query}\")\n",
    "        \n",
    "        matched_docs = retriever.get_relevant_documents(query)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in matched_docs])\n",
    "\n",
    "        final_response = qa_chain.run(context=context, query=query)\n",
    "\n",
    "        print(\"\\nüìÑ === Retrieved Test Case IDs ===\")\n",
    "        print(final_response)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! I'm OM-Bot. Please enter your Order Number along with your query.\n",
      "Type 'bye' to exit.\n",
      "\n",
      "‚úÖ Ready to search test cases! Type 'exit' to stop.\n",
      "\n",
      "\n",
      "üìÑ === Retrieved Test Case IDs ===\n",
      "1. TC_ID: CPQ-SILO-RT-20, CPQ_RT_20_SILO_CLOUD_PublicSectorPaymentTerms - This test case is relevant because it contains the keyword \"Publicsector\" and it's related to the Cloud product line (LOB), which seems to be a common factor across many of your test cases.\n",
      "\n",
      "  2. TC_ID: CPQ-SILO-RT-DD11, CPQ_RT_DD11_20B_SILO_CLOUD_PublicSectorPaymentTerms_DE - This test case is relevant because it also contains the keyword \"Publicsector\" and it's related to the Cloud product line (LOB) for a German (DE) context, which might be important depending on your requirements.\n",
      "\n",
      "  3. TC_ID: CPQ-SILO-RT-DD10, CPQ_RT_DD10_20A_SILO_CLOUD_PublicSectorPaymentTerms_CA - This test case is relevant because it contains the keyword \"Publicsector\" and it's related to the Cloud product line (LOB) for a Canadian (CA) context.\n",
      "\n",
      "  4. TC_ID: CPQ-SILO-RT-DD12, CPQ_RT_DD12_20C_SILO_CLOUD_PublicSectorPaymentTerms_UK - This test case is relevant because it contains the keyword \"Publicsector\" and it's related to the Cloud product line (LOB) for a UK context.\n",
      "\n",
      "All of these test cases seem to be particularly relevant as they explicitly mention the keyword \"Publicsector\" and are associated with the Cloud product line, which might be the focus of your query.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! I'm OM-Bot. Please enter your Order Number along with your query.\n",
      "Type 'bye' to exit.\n",
      "\n",
      "‚úÖ Ready to search test cases! Type 'exit' to stop.\n",
      "\n",
      "\n",
      "üîë Keywords entered: ucm\n",
      "\n",
      "üìÑ === Retrieved Test Case IDs ===\n",
      "1. CPQ-SILO-RT-UCM4: This test case is relevant because it involves the UCM product configuration and Direct Onboarding in the Cloud sales channel, which are keywords present in the query.\n",
      "\n",
      "  2. CPQ-SILO-RT-UCM3: This test case also involves the UCM product configuration and Direct Onboarding in the Cloud sales channel, making it relevant to the query.\n",
      "\n",
      "  3. CPQ-SILO-RT-UCM2: Although this test case does not explicitly mention \"UCM4\", it involves the same \"UCM\" product and Direct Onboarding in the Cloud sales channel, which makes it related to the query.\n",
      "\n",
      "  4. CPQ-SILO-RT-CTP-002: While this test case is about UCM-PAYG rather than UCM4, it does involve the UCM product and Direct Onboarding in the Cloud sales channel, making it relevant to the query.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! I'm QA Agent. Please enter your keywords to retrieve the corresponding TC_ID's.\n",
      "Type 'bye' to exit.\n",
      "\n",
      "‚úÖ Ready to search test cases! Type 'exit' to stop.\n",
      "\n",
      "\n",
      "üîë Keywords entered: Professional Services\n",
      "\n",
      "üìÑ === Retrieved Test Case IDs ===\n",
      " Based on the keyword \"Professional Services\", the following test cases are most relevant:\n",
      "\n",
      "1. TC_ID: CPQ-SILO-RT-15 - This test case includes the \"Product Configuration: Professional Services\" and is associated with the \"LOB: Cloud\".\n",
      "2. TC_ID: CPQ-SILO-RT-CTP-QA2 - This test case also includes the \"Product Configuration: Professional Services\" and is associated with the \"LOB: Cloud\".\n",
      "3. TC_ID: CPQ-SILO-RT-31 - While this test case specifies a specific product type (\"Consulting Product\") within professional services, it still pertains to professional services as a whole.\n",
      "4. TC_ID: CPQ-SILO-RT-23 - This test case includes the \"Product Configuration: Professional Services\" and is associated with the \"LOB: Cloud\".\n",
      "5. TC_ID: CPQ-SILO-RT-35 - Although this test case specifies a specific product type (\"Consulting Product\") within professional services, it still pertains to professional services as a whole.\n",
      "6. TC_ID: CPQ-SILO-RT-18 - This test case includes the \"Product Configuration: Professional Services\" and is associated with the \"LOB: Cloud\".\n",
      "7. TC_ID: CPQ-SILO-RT-DD10 - Although this test case does not explicitly mention \"Professional Services\", it does include \"LOB: Cloud\" and professional services are a common type of product in the cloud domain.\n",
      "8. TC_ID: CPQ-SILO-RT-20 - This test case includes the \"Product Configuration: Professional Services\" and is associated with the \"LOB: Cloud\".\n",
      "\n",
      "In summary, the relevant TC_IDs for the query are: CPQ-SILO-RT-15, CPQ-SILO-RT-CTP-QA2, CPQ-SILO-RT-31, CPQ-SILO-RT-23, CPQ-SILO-RT-18, CPQ-SILO-RT-DD10, and CPQ-SILO-RT-20.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "üîë Keywords entered: UCM\n",
      "\n",
      "üìÑ === Retrieved Test Case IDs ===\n",
      "1. CPQ-SILO-RT-UCM3: This test case is relevant as it involves the UCM product in a Direct Onboarding scenario for Cloud sales channel. It also includes SaaS, which is mentioned in the query.\n",
      "\n",
      "  2. CPQ-SILO-RT-UCM4: This test case is relevant because it deals with the UCM product, specifically in a Direct Onboarding scenario for Cloud sales channel, and it mentions Fusion Services (FaaS), which is also part of the query.\n",
      "\n",
      "  3. CPQ-SILO-RT-UCM2: Although this test case does not directly mention UCM, it involves a product configuration that includes UCM - Funded Allocation. Since the query mentioned UCM, this test case might be relevant if there's an overlap in testing for UCM configurations.\n",
      "\n",
      "  4. CPQ-SILO-RT-09: This test case is relevant as it deals with the UCM product in a Partner Onboarding scenario for Cloud sales channel. However, it does not explicitly mention any additional services such as SaaS or FaaS.\n",
      "\n",
      "  5. CPQ-SILO-RT-UCM1: This test case involves the UCM product in a Direct Onboarding scenario for Cloud sales channel with a monthly billing option (UCM-Monthly), which is not mentioned in the query.\n",
      "\n",
      "  6. CPQ-SILO-RT-DD06: This test case deals with the UCM product in a Partner Onboarding scenario for Cloud sales channel, similar to TC_ID: CPQ-SILO-RT-09, but it's for a different region (CA). It does not mention any additional services like SaaS or FaaS.\n",
      "\n",
      "  7. CPQ-SILO-RT-CTP-002: This test case is relevant as it involves the UCM product in a Direct Onboarding scenario for Cloud sales channel, but it includes a Copy Quote operation and mentions PAYG (Pay As You Go), which is not part of the query.\n",
      "\n",
      "The TC_IDs that match the query are: CPQ-SILO-RT-UCM3, CPQ-SILO-RT-UCM4, CPQ-SILO-RT-UCM2, CPQ-SILO-RT-09.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Create Jenkins agent to trigger a build with the TC_ID's generated\n",
    "# from the conversation\n",
    "def trigger_jenkins_build(tc_ids):\n",
    "    \"\"\"\n",
    "    Triggers a Jenkins build with the given TC_IDs.\n",
    "\n",
    "    Args:\n",
    "        tc_ids (list): List of TC_IDs to pass to the Jenkins job.\n",
    "    \"\"\"\n",
    "    if not tc_ids:\n",
    "        print(\"No TC_IDs provided to trigger the Jenkins build.\")\n",
    "        return\n",
    "\n",
    "    jenkins_url = \"http://phoenix172606.ad1.fusionappsdphx1.oraclevcn.com:8080\"\n",
    "    jenkins_user = \"admin\"\n",
    "    jenkins_token = \"jenkins_token\"\n",
    "    params = {\n",
    "        \"TC_IDs\": \",\".join(tc_ids)  # Pass TC_IDs as a comma-separated string\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(jenkins_url, auth=(jenkins_user, jenkins_token), params=params)\n",
    "        if response.status_code == 201:\n",
    "            print(\"Jenkins build triggered successfully!\")\n",
    "        else:\n",
    "            print(f\"Failed to trigger Jenkins build. Status code: {response.status_code}, Response: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while triggering the Jenkins build: {e}\")\n",
    "# def trigger_jenkins_build(tc_ids):\n",
    "#     # Code to trigger Jenkins build with the TC_IDs\n",
    "#     pass\n",
    "# Conversation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
